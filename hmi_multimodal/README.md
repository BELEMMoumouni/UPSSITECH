# HMI-multimodal

## Project

The goal of this project is to specify, design and implement a multimodal fusion engine to interact with a drawing palette 
engine to interact with a drawing palette that has no buttons. To create and 
move shapes on the palette you will use the following modalities:
1. Speech recognition thanks to the speech recognition engine (with for example 
the use of the ivy sra5 agent) 
2. Gesture recognition with the 2D gesture recognition palette (your ivy 
$1Recognizer or ICAR agent - see below -)
3. Pointing (mouse) on the drawing palette
The objective is to develop a fusion engine of the different modalities allowing to approach 
the famous "put that there" (see link below), one of the first multimodal interaction techniques
proposed by MIT about 40 years ago

link: https://www.youtube.com/watch?v=RyBEUyEtxQo

## How to run

* You just need to download or git clone
* Execute (double click ) the .bat file ( run.bat).
* Make sure, processing 4 is installed and in the directory PutThatThere run the file PutThatThere.pde .

## Demos
I did some videos demo you could see in /Demos or directly on my Youtube channel :https://youtu.be/QzJ53f-3rpY this link https://youtu.be/QamJEru_Y34 for QUIT option.

## Conception and implementation
To understand how all of this has been done, have a see in the pdf file PutThatThere.pdf which is /Documents and also the initial project done by my teacher M.Philippe Truillet. 

